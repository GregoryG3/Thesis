{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNG3+zgtny5DvSKqX0DK7oI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GregoryG3/Thesis/blob/main/3_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries"
      ],
      "metadata": {
        "id": "1YaMuWBAXXjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install python-docx"
      ],
      "metadata": {
        "id": "mhd4J0KUO_2m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "sQrZGqQbXVLv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "from os.path import join\n",
        "\n",
        "import re\n",
        "from scipy.stats import describe\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# from docx import Document\n",
        "# from docx.shared import Pt\n",
        "# from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "# from docx.oxml.ns import qn\n",
        "# from docx.oxml import OxmlElement\n",
        "\n",
        "# import string\n",
        "# import nltk\n",
        "# from nltk.util import ngrams\n",
        "# from nltk.corpus import stopwords\n",
        "# from collections import Counter\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# from matplotlib.lines import Line2D\n",
        "# from wordcloud import WordCloud\n",
        "# # from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "HnfAwceGXwAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/Thesis/Data\"\n",
        "FEEDBACK_DIR = join(PROJECT_DIR, \"Feedback data\")\n",
        "PROCESSED_DIR = join(PROJECT_DIR, \"Processed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9yTvjE3X25m",
        "outputId": "0a9f4bfa-9bc4-48be-a9c6-9937c4c4ec12"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the AB feedback dataset with predicted snetiments, topics and motives:"
      ],
      "metadata": {
        "id": "bi8XNyoUsZR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_dataset = pd.read_csv(join(PROCESSED_DIR, \"ab_predicted_2.csv\"), encoding='latin1')\n",
        "## finalnie trzeba pobrac plik: ab_predicted_final.csv"
      ],
      "metadata": {
        "id": "1bDcblBQ8DTn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset with manually coded\n",
        " data and whole Ab_feedback for further processing:\n",
        "\n"
      ],
      "metadata": {
        "id": "iTKPvue3mGMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "manually_coded = pd.read_csv(join(PROJECT_DIR,\"Annotation data/manual_coding_majority_vote_2000_texts.csv\"), encoding='latin1')\n",
        "ab_text_feedback = pd.read_csv(join(FEEDBACK_DIR, \"ab_selected_feedback_data.csv\"), encoding='latin1')"
      ],
      "metadata": {
        "id": "U65qk9MBmIPj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the AB items"
      ],
      "metadata": {
        "id": "6uk4Sf33Rtrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab_items = pd.read_csv(join(FEEDBACK_DIR,\"ab_items.csv\"), encoding='latin1')"
      ],
      "metadata": {
        "id": "n5CmW7yBRvzc"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "LXLgy6LHVNic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the manually coded data to be joined back in:\n"
      ],
      "metadata": {
        "id": "JM5jnSw1GeSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where global_id is in manually_coded\n",
        "manually_coded_extra_info = ab_text_feedback[ab_text_feedback['global_id'].isin(manually_coded['global_id'])]\n",
        "\n",
        "# Merge tables based on the 'global_id' column\n",
        "col = ['global_id', 't_communication', 't_payment', 't_refund',\n",
        "       't_price', 't_value', 't_shipping', 't_product', 't_feedback',\n",
        "       't_vendor', 't_generic', 't_overall', 'pos_neg',\n",
        "       'm_help_other_buyer', 'm_avoid_harm_seler', 'm_help_seller',\n",
        "       'm_rew_pun_seller', 'm_reach_seller', 'm_express_emo', 'm_share_facts']\n",
        "\n",
        "manually_coded_combi = pd.merge(manually_coded_extra_info.iloc[:, [0, 1, 3, 4, 5, 6, 7, 8]],\n",
        "                                manually_coded.loc[:, col],\n",
        "                                on='global_id')\n",
        "\n",
        "# Tidy up the dates\n",
        "manually_coded_combi.loc[:, 'date_left'] = pd.to_datetime(manually_coded_combi['date_left'].str.slice(stop=-6), format='%b %d, %Y', errors='coerce').dt.date\n"
      ],
      "metadata": {
        "id": "nljiIGHYGmTn"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join the prediction and manually coded subset:\n"
      ],
      "metadata": {
        "id": "zZJnRQQtDhrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_dataset['origin'] = \"prediction\"\n",
        "manually_coded_combi['origin'] = \"manual\"\n",
        "\n",
        "# Rename the column to 'm_avoid_harm_seller' - we have a typo\n",
        "manually_coded_combi = manually_coded_combi.rename(columns={'m_avoid_harm_seler': 'm_avoid_harm_seller'})\n",
        "\n",
        "full_dataset = pd.concat([manually_coded_combi, prediction_dataset], axis=0)"
      ],
      "metadata": {
        "id": "-QGc9pBDFadB"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change type of columns"
      ],
      "metadata": {
        "id": "ZI6TH64IQFBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the columns to convert\n",
        "cols_to_convert = full_dataset.columns[8:27]\n",
        "\n",
        "# Function to convert to Int64 if the value is finite, otherwise keep NaN\n",
        "def to_int_if_finite(series):\n",
        "    return series.apply(lambda x: int(x) if pd.notna(x) and np.isfinite(x) else pd.NA).astype('Int64')\n",
        "\n",
        "# Apply the conversion to the specified columns with a progress bar\n",
        "for col in tqdm(cols_to_convert, desc=\"Converting columns in full_dataset\"):\n",
        "    full_dataset[col] = to_int_if_finite(full_dataset[col])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7w39kKrPE28",
        "outputId": "73343967-b99f-4f5c-fbab-0bb452177ffd"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting columns in full_dataset: 100%|██████████| 19/19 [00:37<00:00,  1.97s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Preparing AB dataset"
      ],
      "metadata": {
        "id": "gsWi7J3-14LW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge two dataset:"
      ],
      "metadata": {
        "id": "QO2Uk2NE6gt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter only AB dataset\n",
        "df_predict_filter = df_predict[df_predict['dataset']=='ab']\n",
        "# remove duplicates from database with items\n",
        "ab_items_no_duplicates = ab_items.drop_duplicates(subset=['itemid'], keep='first')\n",
        "\n",
        "# Convert 'itemid' columns to string, handling NaN values\n",
        "def is_finite(value):\n",
        "    try:\n",
        "        return np.isfinite(float(value))\n",
        "    except (ValueError, TypeError):\n",
        "        return False\n",
        "\n",
        "mask_finite = df_predict_filter['itemid'].apply(is_finite)\n",
        "df_predict_filter.loc[mask_finite, 'itemid'] = (\n",
        "    df_predict_filter.loc[mask_finite, 'itemid']\n",
        "    .astype(float)\n",
        "    .astype(int)\n",
        "    .astype(str)\n",
        ")\n",
        "\n",
        "ab_items_no_duplicates.loc[:,'itemid'] = ab_items_no_duplicates['itemid'].astype(str)\n",
        "\n",
        "# Merge the entire datasets based on 'itemid'\n",
        "ab_feedback = pd.merge(df_predict_filter,\n",
        "                       ab_items_no_duplicates,\n",
        "                       on=['itemid','seller'],\n",
        "                       how='left')\n",
        "\n",
        "ab_feedback = ab_feedback[ab_feedback['symbols_only']=='no']\n",
        "ab_feedback_for_prediciton = ab_feedback.drop(columns=['symbols_only', 'dataset','buyer', 'cat2'])\n",
        "ab_feedback_for_prediciton = ab_feedback_for_prediciton.dropna(subset=['category'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt9EW9ShPnUK",
        "outputId": "0482e50d-0724-4d45-a76a-c20f8f27d79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-9ecb390f01f4>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_predict_filter.loc[mask_finite, 'itemid'] = (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # filter only AB dataset\n",
        "# df_predict_filter = df_predict[df_predict['dataset']=='ab']\n",
        "# # remove duplicates from database with items\n",
        "# # ab_items_no_duplicates = ab_items.drop_duplicates(subset=['itemid'], keep='first')\n",
        "\n",
        "# # Convert 'itemid' columns to string, handling NaN values\n",
        "# def is_finite(value):\n",
        "#     try:\n",
        "#         return np.isfinite(float(value))\n",
        "#     except (ValueError, TypeError):\n",
        "#         return False\n",
        "\n",
        "# mask_finite = df_predict_filter['itemid'].apply(is_finite)\n",
        "# df_predict_filter.loc[mask_finite, 'itemid'] = (\n",
        "#     df_predict_filter.loc[mask_finite, 'itemid']\n",
        "#     .astype(float)\n",
        "#     .astype(int)\n",
        "#     .astype(str)\n",
        "# )\n",
        "\n",
        "# ab_items.loc[:,'itemid'] = ab_items_no_duplicates['itemid'].astype(str)\n",
        "\n",
        "# df_predict_filter['price'] = pd.to_numeric(df_predict_filter['price'], errors='coerce')\n",
        "# ab_items['price'] = pd.to_numeric(ab_items['price'], errors='coerce')\n",
        "# # ab_items_no_duplicates.loc[:,'itemid'] = ab_items_no_duplicates['itemid'].astype(str)\n",
        "\n",
        "# # Merge the entire datasets based on 'itemid'\n",
        "# ab_feedback = pd.merge(df_predict_filter,\n",
        "#                       #  ab_items_no_duplicates,\n",
        "#                        ab_items,\n",
        "#                        on=['itemid','seller', 'price'],\n",
        "#                        how='left')\n",
        "\n",
        "# ab_feedback = ab_feedback[ab_feedback['symbols_only']=='no']\n",
        "# ab_feedback_for_prediciton = ab_feedback.drop(columns=['symbols_only', 'dataset','buyer', 'cat2'])\n",
        "# ab_feedback_for_prediciton = ab_feedback_for_prediciton.dropna(subset=['category'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZERAM6OZ8SFQ",
        "outputId": "ee8546cb-31a9-4e48-df69-d6c47c7b1719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-8141147f3b78>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_predict_filter.loc[mask_finite, 'itemid'] = (\n",
            "<ipython-input-60-8141147f3b78>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_predict_filter['price'] = pd.to_numeric(df_predict_filter['price'], errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YNo9Txhz5CTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to compare two columns, including NaNs\n",
        "def compare_columns_with_nan(df, col1, col2):\n",
        "    return df.apply(lambda x: x[col1] == x[col2] or (pd.isna(x[col1]) and pd.isna(x[col2])), axis=1)\n",
        "\n",
        "# Apply the function to the DataFrame\n",
        "comparison_with_nan = compare_columns_with_nan(ab_feedback_for_prediciton, 'seller_x', 'seller_y')\n",
        "\n",
        "comparison_with_nan.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "6GHw1eqP25Yf",
        "outputId": "e3e31860-26c3-447b-cf7d-ae03f65a00a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'seller_x'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'seller_x'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-e7731d64f8f5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Apply the function to the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcomparison_with_nan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_columns_with_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab_feedback_for_prediciton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seller_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seller_y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcomparison_with_nan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-e7731d64f8f5>\u001b[0m in \u001b[0;36mcompare_columns_with_nan\u001b[0;34m(df, col1, col2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define a function to compare two columns, including NaNs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompare_columns_with_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Apply the function to the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9422\u001b[0m         )\n\u001b[0;32m-> 9423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9425\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-e7731d64f8f5>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define a function to compare two columns, including NaNs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompare_columns_with_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Apply the function to the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'seller_x'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iTHWBnvf4_75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the file"
      ],
      "metadata": {
        "id": "zwulovD2bOT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset.to_csv(join(PROCESSED_DIR, \"full_dataset.csv\"), index=False)"
      ],
      "metadata": {
        "id": "MYnFyQkSbOT1"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}